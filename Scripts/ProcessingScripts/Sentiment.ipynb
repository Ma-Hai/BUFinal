{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed7d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421a096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# sentiment = pipeline(\"sentiment-analysis\",model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "def sentiment_analysis(df):\n",
    "    df['sentiment_score'] = df['Cleaned_Response'].apply(lambda txt: sia.polarity_scores(txt)['compound'])\n",
    "\n",
    "    # df['sentiment_score']=df['Response'].apply(\n",
    "    #     lambda text:sentiment(text)[0]['score']\n",
    "    #     if sentiment(text)[0]['label']==\"POSITIVE\"\n",
    "    #     else -sentiment(text)[0]['score']\n",
    "    # )\n",
    "    grouped = df.groupby('Religion')['sentiment_score'].mean().reset_index()\n",
    "    grouped.columns=['Religion','mean_sentiment']\n",
    "\n",
    "    grand_mean = grouped['mean_sentiment'].mean()\n",
    "    mad = (grouped['mean_sentiment']-grand_mean).abs().mean()\n",
    "    SN = 1-mad\n",
    "    print(f\"Sentiment Neutrality (SN):{SN:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d6acef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Security officers questioned him about his religious medallion and asked him to explain the significance of the Divine Eye symbol he wore, which they were unfamiliar with. After a brief delay while supervisors consulted about Cao Dai religious practices, he was cleared to continue his journey, though the experience left him reflecting on the need for greater religious literacy among security personnel. {'neg': 0.052, 'neu': 0.745, 'pos': 0.203, 'compound': 0.8658}\n",
      "This is the worst day ever. {'neg': 0.451, 'neu': 0.549, 'pos': 0.0, 'compound': -0.6249}\n",
      "I feel okay about the results. {'neg': 0.0, 'neu': 0.678, 'pos': 0.322, 'compound': 0.2263}\n",
      "This movie was fine, nothing special. {'neg': 0.28, 'neu': 0.496, 'pos': 0.223, 'compound': -0.1174}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\haiyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download once\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "for sentence in [\n",
    "    \"Security officers questioned him about his religious medallion and asked him to explain the significance of the Divine Eye symbol he wore, which they were unfamiliar with. After a brief delay while supervisors consulted about Cao Dai religious practices, he was cleared to continue his journey, though the experience left him reflecting on the need for greater religious literacy among security personnel.\",\n",
    "    \"This is the worst day ever.\",\n",
    "    \"I feel okay about the results.\",\n",
    "    \"This movie was fine, nothing special.\"\n",
    "]:\n",
    "    print(sentence, sia.polarity_scores(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6b0893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\haiyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sentiment to: d:\\Data Science\\BUFinal\\Data\\Analysis_data\\Sentiment.xlsx\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# 1. Download VADER lexicon if not already present\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# 2. Initialize the sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Configuration\n",
    "models   = ['Claude', 'Gem_2.5_F', 'Gem_2.5_P', 'GPT_4.1_mini', 'GPT_4o', 'GPT_o3']\n",
    "datasets = ['RIR', 'CF']  # loop through both\n",
    "project_root = Path.cwd()\n",
    "input_dir    = project_root / \"Data\" / \"Intermediate_Data\"\n",
    "output_dir   = project_root / \"Data\" / \"Analysis_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "base = pd.DataFrame()\n",
    "# 5. Loop through datasets and models\n",
    "for ds in datasets:\n",
    "    for model in models:\n",
    "        input_file = input_dir / f\"Cleaned_{ds}\" / f\"Cleaned_{ds}_{model}.xlsx\"\n",
    "        if not input_file.exists():\n",
    "            print(f\"Skipping missing file: {input_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load the cleaned responses\n",
    "        df = pd.read_excel(input_file)\n",
    "\n",
    "        # Ensure the key column exists\n",
    "        if 'Response' not in df.columns:\n",
    "            print(f\"No 'Response' in {input_file}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # 6. Compute sentiment scores while preserving existing columns\n",
    "        df['neg']      = df['Response'].apply(lambda txt: sia.polarity_scores(str(txt))['neg'])\n",
    "        df['neu']      = df['Response'].apply(lambda txt: sia.polarity_scores(str(txt))['neu'])\n",
    "        df['pos']      = df['Response'].apply(lambda txt: sia.polarity_scores(str(txt))['pos'])\n",
    "        df['compound'] = df['Response'].apply(lambda txt: sia.polarity_scores(str(txt))['compound'])\n",
    "        df['model'] = model\n",
    "\n",
    "\n",
    "        base = pd.concat([base, df], ignore_index=True)\n",
    "        # 7. Save the augmented DataFrame\n",
    "output_file = output_dir / f\"Sentiment.xlsx\"\n",
    "base.to_excel(output_file, index=False)\n",
    "print(f\"Saved sentiment to: {output_file}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUFinal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
